{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe47340-079c-4dcc-bcda-d3874ffba07d",
   "metadata": {},
   "source": [
    "# Neural Networks Hyperparameter Tuning with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d453f2d-d4d4-4d26-b1e6-2ce4f9e6eb59",
   "metadata": {},
   "source": [
    "Hyperparameters are a set of parameters whose value controls the learning process of the model. The performance of models can be greatly improved by tuning their hyperparameters. Tuning hyperparameters means you are trying to find out the set of optimal parameters, giving you better performance than the default hyperparameters of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77518a-8cf2-46f5-add6-38d876a6c638",
   "metadata": {},
   "source": [
    "### 1. Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1aed2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib==3.8.2\n",
    "# !pip install numpy==1.26.2\n",
    "# !pip install pandas==2.1.4\n",
    "# !pip install scikit_learn==1.4.2\n",
    "# !pip install seaborn==0.13.2\n",
    "# !pip install torch==2.2.2\n",
    "# !pip install torchvision==0.17.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7eaed9",
   "metadata": {
    "id": "7776c2d8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6880fa09",
   "metadata": {
    "id": "df8676e2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Input/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ddc24d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "77378ce7",
    "outputId": "373d002f-9293-4982-c6de-19f046bd96ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>phone_no</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>no_of_days_subscribed</th>\n",
       "      <th>multi_screen</th>\n",
       "      <th>mail_subscribed</th>\n",
       "      <th>weekly_mins_watched</th>\n",
       "      <th>minimum_daily_mins</th>\n",
       "      <th>maximum_daily_mins</th>\n",
       "      <th>weekly_max_night_mins</th>\n",
       "      <th>videos_watched</th>\n",
       "      <th>maximum_days_inactive</th>\n",
       "      <th>customer_support_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>100198</td>\n",
       "      <td>409-8743</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>62</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>148.35</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16.81</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>100643</td>\n",
       "      <td>340-5930</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>149</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>294.45</td>\n",
       "      <td>7.7</td>\n",
       "      <td>33.37</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  customer_id  phone_no  gender  age  no_of_days_subscribed  \\\n",
       "0  2015       100198  409-8743  Female   36                     62   \n",
       "1  2015       100643  340-5930  Female   39                    149   \n",
       "\n",
       "  multi_screen mail_subscribed  weekly_mins_watched  minimum_daily_mins  \\\n",
       "0           no              no               148.35                12.2   \n",
       "1           no              no               294.45                 7.7   \n",
       "\n",
       "   maximum_daily_mins  weekly_max_night_mins  videos_watched  \\\n",
       "0               16.81                     82               1   \n",
       "1               33.37                     87               3   \n",
       "\n",
       "   maximum_days_inactive  customer_support_calls  churn  \n",
       "0                    4.0                       1    0.0  \n",
       "1                    3.0                       2    0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2462d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLiXthsGRdk8",
    "outputId": "e5bf8fdf-59ba-4369-a425-f36b36c3aa21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb39f38f-82ab-419a-b84e-f6c624a13165",
   "metadata": {},
   "source": [
    "#### 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e335f3f",
   "metadata": {
    "id": "290beada"
   },
   "outputs": [],
   "source": [
    "#Dropping the columns which doesnot make any sense in prediction\n",
    "data = df.drop([\"customer_id\", \"phone_no\", \"year\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c78bc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "e4c57431",
    "outputId": "5252ffac-163a-4dae-ae42-9eaa60389182"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>no_of_days_subscribed</th>\n",
       "      <th>multi_screen</th>\n",
       "      <th>mail_subscribed</th>\n",
       "      <th>weekly_mins_watched</th>\n",
       "      <th>minimum_daily_mins</th>\n",
       "      <th>maximum_daily_mins</th>\n",
       "      <th>weekly_max_night_mins</th>\n",
       "      <th>videos_watched</th>\n",
       "      <th>maximum_days_inactive</th>\n",
       "      <th>customer_support_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>94</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>178.05</td>\n",
       "      <td>10.4</td>\n",
       "      <td>20.18</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Male</td>\n",
       "      <td>37</td>\n",
       "      <td>73</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>326.70</td>\n",
       "      <td>10.3</td>\n",
       "      <td>37.03</td>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  age  no_of_days_subscribed multi_screen mail_subscribed  \\\n",
       "1998   Male   40                     94           no              no   \n",
       "1999   Male   37                     73           no              no   \n",
       "\n",
       "      weekly_mins_watched  minimum_daily_mins  maximum_daily_mins  \\\n",
       "1998               178.05                10.4               20.18   \n",
       "1999               326.70                10.3               37.03   \n",
       "\n",
       "      weekly_max_night_mins  videos_watched  maximum_days_inactive  \\\n",
       "1998                    100               6                    NaN   \n",
       "1999                     89               6                    3.0   \n",
       "\n",
       "      customer_support_calls  churn  \n",
       "1998                       3    0.0  \n",
       "1999                       1    1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30172525",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "92e4a959",
    "outputId": "eef002b6-c397-4f1b-cc25-54fbe9ada622"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c261496",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5bd95ab",
    "outputId": "5fcc1678-6abf-4ae2-ee45-bed10309d870",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                    24\n",
       "age                        0\n",
       "no_of_days_subscribed      0\n",
       "multi_screen               0\n",
       "mail_subscribed            0\n",
       "weekly_mins_watched        0\n",
       "minimum_daily_mins         0\n",
       "maximum_daily_mins         0\n",
       "weekly_max_night_mins      0\n",
       "videos_watched             0\n",
       "maximum_days_inactive     28\n",
       "customer_support_calls     0\n",
       "churn                     35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking null values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0b05986",
   "metadata": {
    "id": "29c1dfbe"
   },
   "outputs": [],
   "source": [
    "#dropping null values\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb066586",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9e96a0a",
    "outputId": "1fa17ceb-4a06-4631-d062-8f248317a7d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of data after dropping null values\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b558f5-322d-48dd-aa8f-317dc2ff0c08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47534919",
    "outputId": "f8222262-a100-4eec-b135-9d84dde4ecad"
   },
   "source": [
    "### 3.Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70c310c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6104bf15",
    "outputId": "457ed169-fa34-4b12-efd3-4462abfa53fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Female' 'Male']\n",
      "['no' 'yes']\n",
      "['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(data[\"gender\"].unique())\n",
    "print(data[\"multi_screen\"].unique())\n",
    "print(data[\"mail_subscribed\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8d35c58",
   "metadata": {
    "id": "b27859ff"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0246dac6",
   "metadata": {
    "id": "f2bce5e1"
   },
   "outputs": [],
   "source": [
    "#label encoding categorical features\n",
    "data[\"gender\"] = le.fit_transform(data[\"gender\"])\n",
    "data[\"multi_screen\"] = le.fit_transform(data[\"multi_screen\"])\n",
    "data[\"mail_subscribed\"] = le.fit_transform(data[\"mail_subscribed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a2821d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "24f4f5b6",
    "outputId": "edddfaff-319f-45f3-bef1-9ea49a57f865",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>no_of_days_subscribed</th>\n",
       "      <th>multi_screen</th>\n",
       "      <th>mail_subscribed</th>\n",
       "      <th>weekly_mins_watched</th>\n",
       "      <th>minimum_daily_mins</th>\n",
       "      <th>maximum_daily_mins</th>\n",
       "      <th>weekly_max_night_mins</th>\n",
       "      <th>videos_watched</th>\n",
       "      <th>maximum_days_inactive</th>\n",
       "      <th>customer_support_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148.35</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16.81</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>294.45</td>\n",
       "      <td>7.7</td>\n",
       "      <td>33.37</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age  no_of_days_subscribed  multi_screen  mail_subscribed  \\\n",
       "0       0   36                     62             0                0   \n",
       "1       0   39                    149             0                0   \n",
       "\n",
       "   weekly_mins_watched  minimum_daily_mins  maximum_daily_mins  \\\n",
       "0               148.35                12.2               16.81   \n",
       "1               294.45                 7.7               33.37   \n",
       "\n",
       "   weekly_max_night_mins  videos_watched  maximum_days_inactive  \\\n",
       "0                     82               1                    4.0   \n",
       "1                     87               3                    3.0   \n",
       "\n",
       "   customer_support_calls  churn  \n",
       "0                       1    0.0  \n",
       "1                       2    0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f06297d0",
   "metadata": {
    "id": "9f45c2a6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a888cd7",
   "metadata": {
    "id": "f1d9ffa7"
   },
   "outputs": [],
   "source": [
    "#dropping categorical columns and keeping numerical columns only\n",
    "data_num = data.drop([\"gender\", \"multi_screen\", \"mail_subscribed\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cb0bbfe",
   "metadata": {
    "id": "b1a4b97d"
   },
   "outputs": [],
   "source": [
    "#scaling numericals columns\n",
    "cols = data_num.columns\n",
    "data_num = scaler.fit_transform(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "463ceb19-86df-4ee6-b972-b417541784d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28125   , 0.25206612, 0.28192702, 0.61      , 0.28185781,\n",
       "       0.30075188, 0.05263158, 0.66666667, 0.11111111, 0.        ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07fd2a44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6969db66",
    "outputId": "f0bc54e3-d539-48e1-863c-f5660d55b5d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'no_of_days_subscribed',\n",
       " 'weekly_mins_watched',\n",
       " 'minimum_daily_mins',\n",
       " 'maximum_daily_mins',\n",
       " 'weekly_max_night_mins',\n",
       " 'videos_watched',\n",
       " 'maximum_days_inactive',\n",
       " 'customer_support_calls',\n",
       " 'churn']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of numerical columns\n",
    "cols = list(cols)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8099fe8",
   "metadata": {
    "id": "132b1bb7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>no_of_days_subscribed</th>\n",
       "      <th>multi_screen</th>\n",
       "      <th>mail_subscribed</th>\n",
       "      <th>weekly_mins_watched</th>\n",
       "      <th>minimum_daily_mins</th>\n",
       "      <th>maximum_daily_mins</th>\n",
       "      <th>weekly_max_night_mins</th>\n",
       "      <th>videos_watched</th>\n",
       "      <th>maximum_days_inactive</th>\n",
       "      <th>customer_support_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.252066</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281927</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.281858</td>\n",
       "      <td>0.300752</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.611570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.559578</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.338346</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender       age  no_of_days_subscribed  multi_screen  mail_subscribed  \\\n",
       "0       0  0.281250               0.252066             0                0   \n",
       "1       0  0.328125               0.611570             0                0   \n",
       "\n",
       "   weekly_mins_watched  minimum_daily_mins  maximum_daily_mins  \\\n",
       "0             0.281927               0.610            0.281858   \n",
       "1             0.559578               0.385            0.559524   \n",
       "\n",
       "   weekly_max_night_mins  videos_watched  maximum_days_inactive  \\\n",
       "0               0.300752        0.052632               0.666667   \n",
       "1               0.338346        0.157895               0.500000   \n",
       "\n",
       "   customer_support_calls  churn  \n",
       "0                0.111111    0.0  \n",
       "1                0.222222    0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cols] = data_num\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2792114b",
   "metadata": {
    "id": "eaab4d76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0.0    1665\n",
       "1.0     253\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e69d1a-e85e-4489-92fe-30abb815cd95",
   "metadata": {},
   "source": [
    "*There is a clear class imbalance here,algorithms may struggle to properly learn and make accurate predictions for the minority class, leading to biased results and reduced performance*\n",
    "- Synthetic Minority Oversampling Technique(SMOTE) method is used to address imbalance datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbd8245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Class Imbalance\n",
    "import imblearn #imbalanced learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84faae4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dx9sEe7rTyjb",
    "outputId": "9eec5497-5b53-4cf8-a33c-87617f2e0b66",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit predictor and target variable\n",
    "x_smote, y_smote = smote.fit_resample(data.iloc[:,0:-1], data['churn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb8f21d-b5ed-43cc-a579-d7e4fc8cbfb2",
   "metadata": {},
   "source": [
    "*fit_resample method fits the SMOTE model and applies it to resample the dataset & finally we get equilized data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f8299b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape 1918\n",
      "Resampled dataset shape 3330\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape', len(data))\n",
    "print('Resampled dataset shape', len(y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb783847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0.0    1665\n",
       "1.0    1665\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking after class balancing\n",
    "y_smote.groupby(y_smote).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ad97359",
   "metadata": {
    "id": "fc4b30f7"
   },
   "outputs": [],
   "source": [
    "# split a dataset into train and test sets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f724e01",
   "metadata": {
    "id": "b3067ab7"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_smote, y_smote, test_size=0.2, random_state=42,\n",
    "                                                    stratify=y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03afd20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n",
      "333\n"
     ]
    }
   ],
   "source": [
    "print((y_test==0).sum())\n",
    "print((y_test==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbb26f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332\n",
      "1332\n"
     ]
    }
   ],
   "source": [
    "print((y_train==0).sum())\n",
    "print((y_train==1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587213e",
   "metadata": {},
   "source": [
    "### 4. Building Sequential Neural Network in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2255e7c3-57f4-4d54-9286-443b3dda7e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2664, 12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6675eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47fab2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]), #12x128\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]), #128x64\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size), #64x2\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d546a63",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Negative Log Likelihood Loss commonly used for classification tasks\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e914627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c592a0e9-2fcb-4366-92f6-0a84be95c9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>no_of_days_subscribed</th>\n",
       "      <th>multi_screen</th>\n",
       "      <th>mail_subscribed</th>\n",
       "      <th>weekly_mins_watched</th>\n",
       "      <th>minimum_daily_mins</th>\n",
       "      <th>maximum_daily_mins</th>\n",
       "      <th>weekly_max_night_mins</th>\n",
       "      <th>videos_watched</th>\n",
       "      <th>maximum_days_inactive</th>\n",
       "      <th>customer_support_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>0</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.305785</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.474059</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.474011</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>0</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608324</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.608317</td>\n",
       "      <td>0.609023</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.346921</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.346915</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.644628</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549031</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.548960</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>1</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.466942</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497434</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.497485</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.268595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584664</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.584675</td>\n",
       "      <td>0.398496</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>1</td>\n",
       "      <td>0.195527</td>\n",
       "      <td>0.535407</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600423</td>\n",
       "      <td>0.735149</td>\n",
       "      <td>0.600439</td>\n",
       "      <td>0.463334</td>\n",
       "      <td>0.201995</td>\n",
       "      <td>0.779301</td>\n",
       "      <td>0.258244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>1</td>\n",
       "      <td>0.377156</td>\n",
       "      <td>0.409229</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255055</td>\n",
       "      <td>0.543448</td>\n",
       "      <td>0.254975</td>\n",
       "      <td>0.291420</td>\n",
       "      <td>0.255896</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>1</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.748005</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.747988</td>\n",
       "      <td>0.323308</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>1</td>\n",
       "      <td>0.292347</td>\n",
       "      <td>0.364487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462315</td>\n",
       "      <td>0.568271</td>\n",
       "      <td>0.462262</td>\n",
       "      <td>0.503549</td>\n",
       "      <td>0.297591</td>\n",
       "      <td>0.610593</td>\n",
       "      <td>0.074765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2664 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age  no_of_days_subscribed  multi_screen  mail_subscribed  \\\n",
       "1108       0  0.234375               0.305785             0                0   \n",
       "1465       0  0.296875               0.264463             0                0   \n",
       "296        0  0.093750               0.227273             0                1   \n",
       "1100       0  0.390625               0.644628             0                1   \n",
       "1489       1  0.218750               0.466942             1                1   \n",
       "...      ...       ...                    ...           ...              ...   \n",
       "966        0  0.312500               0.268595             0                0   \n",
       "2114       1  0.195527               0.535407             1                1   \n",
       "2595       1  0.377156               0.409229             0                1   \n",
       "1043       1  0.203125               0.636364             0                0   \n",
       "2496       1  0.292347               0.364487             0                1   \n",
       "\n",
       "      weekly_mins_watched  minimum_daily_mins  maximum_daily_mins  \\\n",
       "1108             0.474059            0.305000            0.474011   \n",
       "1465             0.608324            0.135000            0.608317   \n",
       "296              0.346921            0.635000            0.346915   \n",
       "1100             0.549031            0.340000            0.548960   \n",
       "1489             0.497434            0.615000            0.497485   \n",
       "...                   ...                 ...                 ...   \n",
       "966              0.584664            0.460000            0.584675   \n",
       "2114             0.600423            0.735149            0.600439   \n",
       "2595             0.255055            0.543448            0.254975   \n",
       "1043             0.748005            0.415000            0.747988   \n",
       "2496             0.462315            0.568271            0.462262   \n",
       "\n",
       "      weekly_max_night_mins  videos_watched  maximum_days_inactive  \\\n",
       "1108               0.285714        0.263158               0.333333   \n",
       "1465               0.609023        0.210526               0.166667   \n",
       "296                0.421053        0.157895               0.666667   \n",
       "1100               0.729323        0.263158               0.333333   \n",
       "1489               0.368421        0.526316               0.666667   \n",
       "...                     ...             ...                    ...   \n",
       "966                0.398496        0.315789               0.500000   \n",
       "2114               0.463334        0.201995               0.779301   \n",
       "2595               0.291420        0.255896               0.500000   \n",
       "1043               0.323308        0.315789               0.500000   \n",
       "2496               0.503549        0.297591               0.610593   \n",
       "\n",
       "      customer_support_calls  \n",
       "1108                0.111111  \n",
       "1465                0.111111  \n",
       "296                 0.111111  \n",
       "1100                0.333333  \n",
       "1489                0.222222  \n",
       "...                      ...  \n",
       "966                 0.222222  \n",
       "2114                0.258244  \n",
       "2595                0.666667  \n",
       "1043                0.222222  \n",
       "2496                0.074765  \n",
       "\n",
       "[2664 rows x 12 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af2c77e0-8798-4b8c-b15f-1ab8a7fbf9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108    0.0\n",
       "1465    0.0\n",
       "296     0.0\n",
       "1100    0.0\n",
       "1489    0.0\n",
       "       ... \n",
       "966     0.0\n",
       "2114    1.0\n",
       "2595    1.0\n",
       "1043    0.0\n",
       "2496    1.0\n",
       "Name: churn, Length: 2664, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfb3269-5b90-411c-8453-d1cd29bd9e21",
   "metadata": {},
   "source": [
    "*converting data into tensor to pass it to pytorch sequential layer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "521f2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "\n",
    "X_train = Tensor(X_train.values)\n",
    "y_train = Tensor(np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46823ece-2e46-49b5-b748-7891f7594d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2344, 0.3058,  ..., 0.2632, 0.3333, 0.1111],\n",
       "        [0.0000, 0.2969, 0.2645,  ..., 0.2105, 0.1667, 0.1111],\n",
       "        [0.0000, 0.0938, 0.2273,  ..., 0.1579, 0.6667, 0.1111],\n",
       "        ...,\n",
       "        [1.0000, 0.3772, 0.4092,  ..., 0.2559, 0.5000, 0.6667],\n",
       "        [1.0000, 0.2031, 0.6364,  ..., 0.3158, 0.5000, 0.2222],\n",
       "        [1.0000, 0.2923, 0.3645,  ..., 0.2976, 0.6106, 0.0748]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa1d7a18-e2cf-4438-bbc0-4687173d490f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0e77828",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 #number of samples fed into the neural network during each training iteration. \n",
    "#TensorDataset is a PyTorch class that allows you to create a dataset from tensors\n",
    "torch_dataset = Data.TensorDataset(X_train, y_train) \n",
    "\n",
    "#loading data for the model\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, num_workers=2,)\n",
    "#Shuffles the data within the dataset before creating batches in each epoch. \n",
    "#Shuffling helps the model learn from different data combinations and improve generalization.\n",
    "#number of worker threads to use for data loading. More is the number, more is the speed when working with large datasets or performing data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3767f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: -0.007886192506856031\n",
      "Training loss: -0.007895764701806748\n",
      "Training loss: -0.007903398436916483\n",
      "Training loss: -0.007913328696031112\n",
      "Training loss: -0.007921786839002604\n",
      "Training loss: -0.007929170252503576\n",
      "Training loss: -0.007936375165307845\n",
      "Training loss: -0.007947716067682157\n",
      "Training loss: -0.007954453685888657\n",
      "Training loss: -0.007963289459188422\n",
      "Training loss: -0.007971852939497601\n",
      "Training loss: -0.00798415205813385\n",
      "Training loss: -0.007990344452696878\n",
      "Training loss: -0.008002885267720208\n",
      "Training loss: -0.00801195593567582\n",
      "Training loss: -0.008023128830813788\n",
      "Training loss: -0.008034409636312776\n",
      "Training loss: -0.008045327186852962\n",
      "Training loss: -0.00805522372817492\n",
      "Training loss: -0.008072458845269572\n",
      "Training loss: -0.008082065608229366\n",
      "Training loss: -0.008094349758582073\n",
      "Training loss: -0.008110308734414814\n",
      "Training loss: -0.008127732498867734\n",
      "Training loss: -0.00814504401238115\n",
      "Training loss: -0.008158082852850447\n",
      "Training loss: -0.008176744275085919\n",
      "Training loss: -0.008193330654689858\n",
      "Training loss: -0.008210457883797609\n",
      "Training loss: -0.008233804188601606\n",
      "Training loss: -0.00825159551503064\n",
      "Training loss: -0.008267422752068923\n",
      "Training loss: -0.008292643772857683\n",
      "Training loss: -0.008315695276310493\n",
      "Training loss: -0.008341421437514079\n",
      "Training loss: -0.008369125134952075\n",
      "Training loss: -0.008397344936121692\n",
      "Training loss: -0.008419267251505866\n",
      "Training loss: -0.008454142770430705\n",
      "Training loss: -0.008483980108309794\n",
      "Training loss: -0.008516898585690392\n",
      "Training loss: -0.008555724165282092\n",
      "Training loss: -0.008588861640509184\n",
      "Training loss: -0.008631389957290512\n",
      "Training loss: -0.008676067710638762\n",
      "Training loss: -0.008719915071049252\n",
      "Training loss: -0.008762715837439976\n",
      "Training loss: -0.008812328962771385\n",
      "Training loss: -0.008861732957241414\n",
      "Training loss: -0.008908383369266807\n",
      "Training loss: -0.008960287246081207\n",
      "Training loss: -0.009019449867822745\n",
      "Training loss: -0.009065918669149324\n",
      "Training loss: -0.00911678286554577\n",
      "Training loss: -0.009169093928895556\n",
      "Training loss: -0.009220858056982001\n",
      "Training loss: -0.009277007288044996\n",
      "Training loss: -0.009328707426159948\n",
      "Training loss: -0.009388062331053588\n",
      "Training loss: -0.009425402045607925\n",
      "Training loss: -0.009483334471334566\n",
      "Training loss: -0.00952823674893594\n",
      "Training loss: -0.0095742978938707\n",
      "Training loss: -0.009631448836476953\n",
      "Training loss: -0.009676413716854635\n",
      "Training loss: -0.009713653486233216\n",
      "Training loss: -0.009760931380339214\n",
      "Training loss: -0.009813714067678194\n",
      "Training loss: -0.00985559915100132\n",
      "Training loss: -0.00988577751515506\n",
      "Training loss: -0.009932249873966069\n",
      "Training loss: -0.009965670090895874\n",
      "Training loss: -0.010017806725638049\n",
      "Training loss: -0.010037061330434438\n",
      "Training loss: -0.01007894381836012\n",
      "Training loss: -0.010118211823719758\n",
      "Training loss: -0.010132817266223667\n",
      "Training loss: -0.010185195205805896\n",
      "Training loss: -0.010208907562333185\n",
      "Training loss: -0.010243518171725688\n",
      "Training loss: -0.010281361415758505\n",
      "Training loss: -0.010310303654756632\n",
      "Training loss: -0.010337449140376874\n",
      "Training loss: -0.010353360873263877\n",
      "Training loss: -0.010402381889991931\n",
      "Training loss: -0.010429674530172491\n",
      "Training loss: -0.010457515559933923\n",
      "Training loss: -0.010479290094282534\n",
      "Training loss: -0.010516755707987078\n",
      "Training loss: -0.010544960988355471\n",
      "Training loss: -0.010566582439003047\n",
      "Training loss: -0.010588590939481696\n",
      "Training loss: -0.0106292151295029\n",
      "Training loss: -0.010651238083660423\n",
      "Training loss: -0.010686114743665175\n",
      "Training loss: -0.010692274964249527\n",
      "Training loss: -0.0107237487002178\n",
      "Training loss: -0.010756774394361823\n",
      "Training loss: -0.010777637809962482\n",
      "Training loss: -0.010789072169018938\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "epochs = 100 #No. of iterations over the intire dataset\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        #Batch of training features & training labels\n",
    "        b_x = batch_x  # No need for Variable in recent PyTorch versions\n",
    "        b_y = batch_y.type(torch.LongTensor)  # Convert batch_y to LongTensor if needed\n",
    "        \n",
    "        # Training pass\n",
    "        # Sets the gradients of the model's parameters to zero before each training iteration. This ensures gradients accumulate properly during backpropagation.\n",
    "        optimizer.zero_grad()\n",
    "        #Passes the batches of data via neural network to get predictions\n",
    "        output = model(b_x)\n",
    "        #Calculates the loss\n",
    "        loss = criterion(output, b_y)\n",
    "        #Performs backpropagation to calculate the gradients of the loss function with respect to the model's parameters.\n",
    "        loss.backward()\n",
    "        #Updates the parameters\n",
    "        optimizer.step()\n",
    "        # Accumulates the training loss for each batch within an epoch.\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        #Average loss each epoch\n",
    "        print(f\"Training loss: {running_loss/len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f08eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = Tensor(X_test.values)\n",
    "y_test = Tensor(np.array(y_test))\n",
    "z = model(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4a27483",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8351d8a6",
    "outputId": "3d57a4f8-4322-4d2e-aba8-7d27d39d0701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Test Data  75.22522522522522\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat = list(z.argmax(1))\n",
    "y_test = list(y_test)\n",
    "\n",
    "print(\"Accuracy Score of Test Data \",accuracy_score(y_test,yhat) * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5111d5d-36b2-4bb5-9a44-f48cca3f5147",
   "metadata": {},
   "source": [
    "- ***Now lets try to optimise it by Hyperparameter Tuning***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b956a",
   "metadata": {},
   "source": [
    "### 5. Hyperparameter Tuning of  Neural Network in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb52381-236c-4f0a-88dc-bce14c157f65",
   "metadata": {},
   "source": [
    "#### a) Dropout\n",
    "- Dropout is a regularization technique used in neural networks to prevent overfitting & improve generalization. During each training iteration, dropout randomly selects neurons and temporarily removes them (sets their outputs to zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "951f0c09-1515-486f-8cf1-34611671e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ded22a26-312f-4ef6-b0a7-1a5d5a433502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (1): Dropout(p=0.2, inplace=False)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (4): Dropout(p=0.1, inplace=False)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_dropout = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]), #12x128\n",
    "                      nn.Dropout(0.2),# During training, 20% of the neurons will be randomly set to 0.\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),#128x64\n",
    "                      nn.Dropout(0.1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size), #64x2\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e80f714c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.Adam(model_dropout.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e94bcbc7-6f17-40a1-b028-ff16b54d2d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: -0.010128693213244458\n",
      "Training loss: -0.011317282355762459\n",
      "Training loss: -0.01159452499301584\n",
      "Training loss: -0.011921010575852953\n",
      "Training loss: -0.012008330373613684\n",
      "Training loss: -0.012069616545070041\n",
      "Training loss: -0.01221499292252658\n",
      "Training loss: -0.012578861625702889\n",
      "Training loss: -0.012572362974241332\n",
      "Training loss: -0.01224568289321464\n",
      "Training loss: -0.012570607322114366\n",
      "Training loss: -0.012724863024087282\n",
      "Training loss: -0.012547322669186749\n",
      "Training loss: -0.012550937923583182\n",
      "Training loss: -0.012772660199049357\n",
      "Training loss: -0.01283361794085832\n",
      "Training loss: -0.012770193519892994\n",
      "Training loss: -0.012754591713259529\n",
      "Training loss: -0.012906977431373196\n",
      "Training loss: -0.012912501354475279\n",
      "Training loss: -0.012743572416427257\n",
      "Training loss: -0.012625824917365122\n",
      "Training loss: -0.012434875173074705\n",
      "Training loss: -0.012747671018849622\n",
      "Training loss: -0.012821195496095193\n",
      "Training loss: -0.012874188254008422\n",
      "Training loss: -0.01304128692225293\n",
      "Training loss: -0.012546795557390104\n",
      "Training loss: -0.012968205586747007\n",
      "Training loss: -0.012801037312627913\n",
      "Training loss: -0.012884824863962224\n",
      "Training loss: -0.012812377566152864\n",
      "Training loss: -0.01282227128833622\n",
      "Training loss: -0.012724535936886841\n",
      "Training loss: -0.012830124826760622\n",
      "Training loss: -0.012926278753323597\n",
      "Training loss: -0.01274124470290479\n",
      "Training loss: -0.012764492281922349\n",
      "Training loss: -0.013093500121219738\n",
      "Training loss: -0.012903025625525293\n",
      "Training loss: -0.012918885472837512\n",
      "Training loss: -0.012924905541959826\n",
      "Training loss: -0.012957891454925766\n",
      "Training loss: -0.012816663999278267\n",
      "Training loss: -0.01278646719885302\n",
      "Training loss: -0.01254400447592721\n",
      "Training loss: -0.012930662827090817\n",
      "Training loss: -0.012750458140094002\n",
      "Training loss: -0.013119533076300635\n",
      "Training loss: -0.012916473229905148\n",
      "Training loss: -0.012713312095886952\n",
      "Training loss: -0.01291570201650396\n",
      "Training loss: -0.012954827453997042\n",
      "Training loss: -0.013034060015692725\n",
      "Training loss: -0.012779893683599637\n",
      "Training loss: -0.013008714415826596\n",
      "Training loss: -0.012910108823139031\n",
      "Training loss: -0.012979605377794386\n",
      "Training loss: -0.012761757001504526\n",
      "Training loss: -0.012850630099887963\n",
      "Training loss: -0.012468214462827277\n",
      "Training loss: -0.01293617216226933\n",
      "Training loss: -0.013024986036367961\n",
      "Training loss: -0.012859349180986215\n",
      "Training loss: -0.012990121301766988\n",
      "Training loss: -0.01285852838654418\n",
      "Training loss: -0.01281044710505832\n",
      "Training loss: -0.013028055138595111\n",
      "Training loss: -0.012838939601952606\n",
      "Training loss: -0.012980772322183615\n",
      "Training loss: -0.012852018704643479\n",
      "Training loss: -0.012589068496012473\n",
      "Training loss: -0.013069122850715934\n",
      "Training loss: -0.013173187705310615\n",
      "Training loss: -0.01310637080902094\n",
      "Training loss: -0.012755388545023429\n",
      "Training loss: -0.012814485476360665\n",
      "Training loss: -0.013017137867731374\n",
      "Training loss: -0.01293457865536034\n",
      "Training loss: -0.012981793521581826\n",
      "Training loss: -0.013143882356785439\n",
      "Training loss: -0.012972598878649978\n",
      "Training loss: -0.013037930625874002\n",
      "Training loss: -0.012870063429122214\n",
      "Training loss: -0.01303728307421143\n",
      "Training loss: -0.01284850138175237\n",
      "Training loss: -0.012877109866063515\n",
      "Training loss: -0.0129267080454855\n",
      "Training loss: -0.013107543279816796\n",
      "Training loss: -0.012841749992277529\n",
      "Training loss: -0.012985343443559812\n",
      "Training loss: -0.012816749155163407\n",
      "Training loss: -0.012859130451629112\n",
      "Training loss: -0.013098369153949234\n",
      "Training loss: -0.01300306566753187\n",
      "Training loss: -0.01288980469331369\n",
      "Training loss: -0.012754700227721676\n",
      "Training loss: -0.01281957981643734\n",
      "Training loss: -0.01306775216762726\n",
      "Training loss: -0.01275218857659234\n"
     ]
    }
   ],
   "source": [
    "epochs = 100 #No. of iterations over the entire dataset\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        #Batch of training features & training labels\n",
    "        b_x = batch_x  # No need for Variable in recent PyTorch versions\n",
    "        b_y = batch_y.type(torch.LongTensor)  # Convert batch_y to LongTensor if needed\n",
    "        \n",
    "        # Training pass\n",
    "        # Sets the gradients of the model's parameters to zero before each training iteration. This ensures gradients accumulate properly during backpropagation.\n",
    "        optimizer.zero_grad()\n",
    "        #Passes the batches of data via neural network to get predictions\n",
    "        output = model_dropout(b_x)\n",
    "        #Calculates the loss\n",
    "        loss = criterion(output, b_y)\n",
    "        #Performs backpropagation to calculate the gradients of the loss function with respect to the model's parameters.\n",
    "        loss.backward()\n",
    "        #Updates the parameters\n",
    "        optimizer.step()\n",
    "        # Accumulates the training loss for each batch within an epoch.\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        #Average loss each epoch\n",
    "        print(f\"Training loss: {running_loss/len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15839cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Test Data  79.87987987987988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_test_tensor = Tensor(X_test.values)\n",
    "y_test = Tensor(np.array(y_test))\n",
    "z = model_dropout(X_test_tensor)\n",
    "\n",
    "yhat = list(z.argmax(1))\n",
    "y_test = list(y_test)\n",
    "\n",
    "print(\"Accuracy Score of Test Data \",accuracy_score(y_test,yhat) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa6cce",
   "metadata": {},
   "source": [
    "#### b) Regularization\n",
    "- Regularization introduces a penalty(weight_decay) to the loss function during training to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5dbab69-ec89-49b9-89b9-4436ab63ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83ecca1f-b85e-4b2a-9e0c-6f808fcdfb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (1): Dropout(p=0.2, inplace=False)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (4): Dropout(p=0.1, inplace=False)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_reg = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]), #12x128\n",
    "                      nn.Dropout(0.2),# During training, 20% of the neurons will be randomly set to 0.\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),#128x64\n",
    "                      nn.Dropout(0.1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size), #64x2\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a356bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "# Regularization\n",
    "from torch import optim\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "# weight_decay adds a small penalty to the loss function to prevent the model from overfitting by discouraging large weights. \n",
    "optimizer = optim.Adam(model_reg.parameters(), lr=0.01, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "824c978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: -0.01036391161136083\n",
      "Training loss: -0.011525721767464199\n",
      "Training loss: -0.012193219327890838\n",
      "Training loss: -0.012405028259074007\n",
      "Training loss: -0.012133402822611926\n",
      "Training loss: -0.012589739272007355\n",
      "Training loss: -0.01269965911949719\n",
      "Training loss: -0.012369676954574414\n",
      "Training loss: -0.01248779246309498\n",
      "Training loss: -0.012702682086297342\n",
      "Training loss: -0.012598239444755577\n",
      "Training loss: -0.012630803337147285\n",
      "Training loss: -0.012803937244164693\n",
      "Training loss: -0.012772959161986102\n",
      "Training loss: -0.01284261235782692\n",
      "Training loss: -0.012834543088176945\n",
      "Training loss: -0.01280310532978705\n",
      "Training loss: -0.012869143830584334\n",
      "Training loss: -0.012852929174542069\n",
      "Training loss: -0.012733954813208308\n",
      "Training loss: -0.012714446150325798\n",
      "Training loss: -0.012784814601903921\n",
      "Training loss: -0.012760059208841296\n",
      "Training loss: -0.012674218250645531\n",
      "Training loss: -0.012891642704561309\n",
      "Training loss: -0.012803253670175513\n",
      "Training loss: -0.012856120484190303\n",
      "Training loss: -0.012585035047015629\n",
      "Training loss: -0.012896583423958169\n",
      "Training loss: -0.012935391372746534\n",
      "Training loss: -0.013063012032179503\n",
      "Training loss: -0.012797409483978341\n",
      "Training loss: -0.012716854746277267\n",
      "Training loss: -0.012622657279531518\n",
      "Training loss: -0.012814784237930367\n",
      "Training loss: -0.012866075645695935\n",
      "Training loss: -0.01293708903116507\n",
      "Training loss: -0.012666054718845242\n",
      "Training loss: -0.012714973016007169\n",
      "Training loss: -0.012874882746566165\n",
      "Training loss: -0.012939792137604218\n",
      "Training loss: -0.012986438141928779\n",
      "Training loss: -0.012757533976623605\n",
      "Training loss: -0.012886586445229905\n",
      "Training loss: -0.012722888172746779\n",
      "Training loss: -0.01281470610751762\n",
      "Training loss: -0.012812893289524514\n",
      "Training loss: -0.012832471513533377\n",
      "Training loss: -0.012781492381303518\n",
      "Training loss: -0.01270042682016218\n",
      "Training loss: -0.012881695597737402\n",
      "Training loss: -0.012763215614868715\n",
      "Training loss: -0.012990803488560984\n",
      "Training loss: -0.012795424653782143\n",
      "Training loss: -0.012807117635244364\n",
      "Training loss: -0.012695958619719153\n",
      "Training loss: -0.012967938439803081\n",
      "Training loss: -0.01302736451675942\n",
      "Training loss: -0.013001558636580859\n",
      "Training loss: -0.012855589546419837\n",
      "Training loss: -0.012924643004083776\n",
      "Training loss: -0.012966570889090633\n",
      "Training loss: -0.012787350327581973\n",
      "Training loss: -0.01287421559517806\n",
      "Training loss: -0.013060343538497662\n",
      "Training loss: -0.01287522390708551\n",
      "Training loss: -0.012761764273092195\n",
      "Training loss: -0.012936574694988606\n",
      "Training loss: -0.01309772932135665\n",
      "Training loss: -0.01304256072541973\n",
      "Training loss: -0.013024046524866923\n",
      "Training loss: -0.012998410397105746\n",
      "Training loss: -0.012973267909463819\n",
      "Training loss: -0.013060228602664248\n",
      "Training loss: -0.012297609367886105\n",
      "Training loss: -0.012575962096900196\n",
      "Training loss: -0.012695942197118077\n",
      "Training loss: -0.012834445447535129\n",
      "Training loss: -0.013093820921293608\n",
      "Training loss: -0.012958728582472415\n",
      "Training loss: -0.012939500177765751\n",
      "Training loss: -0.01308264113492794\n",
      "Training loss: -0.012975587769671603\n",
      "Training loss: -0.012938440204024673\n",
      "Training loss: -0.013003967970878154\n",
      "Training loss: -0.013145869312522648\n",
      "Training loss: -0.013155156136812033\n",
      "Training loss: -0.013088938710209844\n",
      "Training loss: -0.012694373592600092\n",
      "Training loss: -0.012918679071618273\n",
      "Training loss: -0.012988951582987388\n",
      "Training loss: -0.012854608262444401\n",
      "Training loss: -0.013037082132276471\n",
      "Training loss: -0.013077158917177905\n",
      "Training loss: -0.013055426558037778\n",
      "Training loss: -0.012853124366329238\n",
      "Training loss: -0.012978794114725726\n",
      "Training loss: -0.012941663821896276\n",
      "Training loss: -0.012843286243823913\n",
      "Training loss: -0.01313052738124544\n"
     ]
    }
   ],
   "source": [
    "epochs = 100 #No. of iterations over the entire dataset\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        #Batch of training features & training labels\n",
    "        b_x = batch_x  # No need for Variable in recent PyTorch versions\n",
    "        b_y = batch_y.type(torch.LongTensor)  # Convert batch_y to LongTensor if needed\n",
    "        \n",
    "        # Training pass\n",
    "        # Sets the gradients of the model's parameters to zero before each training iteration. This ensures gradients accumulate properly during backpropagation.\n",
    "        optimizer.zero_grad()\n",
    "        #Passes the batches of data via neural network to get predictions\n",
    "        output = model_reg(b_x)\n",
    "        #Calculates the loss\n",
    "        loss = criterion(output, b_y)\n",
    "        #Performs backpropagation to calculate the gradients of the loss function with respect to the model's parameters.\n",
    "        loss.backward()\n",
    "        #Updates the parameters\n",
    "        optimizer.step()\n",
    "        # Accumulates the training loss for each batch within an epoch.\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        #Average loss each epoch\n",
    "        print(f\"Training loss: {running_loss/len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5fc12823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Test Data  81.08108108108108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_test_tensor = Tensor(X_test.values)\n",
    "y_test = Tensor(np.array(y_test))\n",
    "z = model_reg(X_test_tensor)\n",
    "\n",
    "yhat = list(z.argmax(1))\n",
    "y_test = list(y_test)\n",
    "\n",
    "print(\"Accuracy Score of Test Data \",accuracy_score(y_test,yhat) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a14a50",
   "metadata": {},
   "source": [
    "### c) Early Stopping\n",
    "- It involves monitoring the model's performance during training and it stops the training process when the performance starts to degrade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4719357e-18c9-4df3-a4cb-d88ff4b8c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24406e84-1537-4f2c-9f08-8e9c6eb1bd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (1): Dropout(p=0.2, inplace=False)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (4): Dropout(p=0.1, inplace=False)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_early_stp = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]), #12x128\n",
    "                      nn.Dropout(0.2),# During training, 20% of the neurons will be randomly set to 0.\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),#128x64\n",
    "                      nn.Dropout(0.1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size), #64x2\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model_early_stp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab2ef9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "# Regularization\n",
    "from torch import optim\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.Adam(model_early_stp.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "401952af",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "min_loss = np.Inf\n",
    "iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5400acc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: -0.013012354505491687\n",
      "Training loss: -0.012883150854984203\n",
      "Training loss: -0.012884700128266046\n",
      "Training loss: -0.01285994117771899\n",
      "Training loss: -0.012886743086415369\n",
      "Training loss: -0.01291240465354633\n",
      "Training loss: -0.012960425345926313\n",
      "Training loss: -0.01292462987047774\n",
      "Training loss: -0.012828754031801367\n",
      "Training loss: -0.012892814459385457\n",
      "Training loss: -0.012816585309512622\n",
      "Training loss: -0.012878406065720337\n",
      "Training loss: -0.012843759366878876\n",
      "Training loss: -0.012878607947368163\n",
      "Training loss: -0.01292590508321384\n",
      "Training loss: -0.012791756059493389\n",
      "Training loss: -0.012829590063016335\n",
      "Training loss: -0.012978931827409132\n",
      "Training loss: -0.01283266182776328\n",
      "Early stopping!\n",
      "Stopped\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "    \n",
    "    \n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    if early_stop:\n",
    "        print(\"Stopped\")\n",
    "        break\n",
    "    else:\n",
    "        for step, (batch_x, batch_y) in enumerate(loader):#ensures that the model is trained on each batch of data in sequence.\n",
    "            #number of iterations = len(X_train) // batch_size\n",
    "            #Batch of training features & training labels\n",
    "            b_x = batch_x  # 64 batch size\n",
    "            b_y = batch_y.type(torch.LongTensor)  # 64 batch size\n",
    "            \n",
    "            # Training pass\n",
    "            # Sets the gradients of the model's parameters to zero before each training iteration. This ensures gradients accumulate properly during backpropagation.\n",
    "            optimizer.zero_grad()\n",
    "            #Passes the batches of data via neural network to get predictions\n",
    "            output = model_dropout(b_x)\n",
    "            #Calculates the loss\n",
    "            loss = criterion(output, b_y)\n",
    "            #Performs backpropagation to calculate the gradients of the loss function with respect to the model's parameters.\n",
    "            loss.backward()\n",
    "            #Updates the parameters\n",
    "            optimizer.step()\n",
    "            # Accumulates the training loss for each batch within an epoch.\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    \n",
    "            if abs(running_loss) < abs(min_loss):\n",
    "                #epochs_no_improve is initialized to 0 at the start of training. \n",
    "                #This variable keeps track of how many consecutive epochs have passed without improvement in the loss.\n",
    "                epochs_no_improve = 0\n",
    "                min_loss = running_loss\n",
    "            else:\n",
    "                epochs_no_improve +=1\n",
    "                iter += 1\n",
    "    \n",
    "            #e > 5 sets threshold for when to start monitoring\n",
    "            if e > 5 and epochs_no_improve ==  epochs:\n",
    "                print('Early stopping!')\n",
    "                #Checks if the epochs_no_improve counter  is equal to the total number of training epochs (epochs). \n",
    "                #If this is true, it suggests no improvement for all epochs.\n",
    "                early_stop = True\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "             print(f\"Training loss: {running_loss/len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "295fa33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Test Data  50.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_test_tensor = Tensor(X_test.values)\n",
    "y_test = Tensor(np.array(y_test))\n",
    "z = model_early_stp(X_test_tensor)\n",
    "\n",
    "yhat = list(z.argmax(1))\n",
    "y_test = list(y_test)\n",
    "\n",
    "print(\"Accuracy Score of Test Data \",accuracy_score(y_test,yhat) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904635b1",
   "metadata": {},
   "source": [
    "### Checkpoint (Loading and saving model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "be0aa3f8-3969-432d-909e-6dd7df77de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7ccdfab-4412-4eac-a484-467ba4943d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=12, out_features=128, bias=True)\n",
      "  (1): Dropout(p=0.2, inplace=False)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (4): Dropout(p=0.1, inplace=False)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_chk = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]), #12x128\n",
    "                      nn.Dropout(0.2),# During training, 20% of the neurons will be randomly set to 0.\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),#128x64\n",
    "                      nn.Dropout(0.1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size), #64x2\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model_chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74b5c597",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "# Regularization\n",
    "from torch import optim\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "# add l2 regularization to optimzer by just adding in a weight_decay \n",
    "optimizer = optim.Adam(model_chk.parameters(), lr=0.01, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "458b5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "path = \"../model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "17e1bd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: -0.010177241498464579\n",
      "Training loss: -0.011243303952453373\n",
      "Training loss: -0.011435661968347189\n",
      "Training loss: -0.01191196304273319\n",
      "Training loss: -0.012231950242598136\n",
      "Training loss: -0.0122596951084094\n",
      "Training loss: -0.012414836624005178\n",
      "Training loss: -0.01247640316550796\n",
      "Training loss: -0.012614822378745666\n",
      "Training loss: -0.01254699296421475\n",
      "Training loss: -0.012681254820601718\n",
      "Training loss: -0.01262057702373098\n",
      "Training loss: -0.012788266301513076\n",
      "Training loss: -0.012804617842396459\n",
      "Training loss: -0.012511991680384398\n",
      "Training loss: -0.01277832995663892\n",
      "Training loss: -0.012733489230230407\n",
      "Training loss: -0.012753739885918729\n",
      "Training loss: -0.012797027669690392\n",
      "Training loss: -0.012704536743887194\n",
      "Training loss: -0.012825142334889364\n",
      "Training loss: -0.012743981795626002\n",
      "Training loss: -0.012567154123439445\n",
      "Training loss: -0.012860982603317982\n",
      "Training loss: -0.012912734671755953\n",
      "Training loss: -0.012496505010951389\n",
      "Training loss: -0.012843794829852588\n",
      "Training loss: -0.012715185525360051\n",
      "Training loss: -0.012745840055448515\n",
      "Training loss: -0.012860289788818932\n",
      "Training loss: -0.012996949456833504\n",
      "Training loss: -0.01263657404674782\n",
      "Training loss: -0.012655028553159387\n",
      "Training loss: -0.012865465056072842\n",
      "Training loss: -0.012983886687247245\n",
      "Training loss: -0.012800127066470482\n",
      "Training loss: -0.012835428409569256\n",
      "Training loss: -0.012846055711890842\n",
      "Training loss: -0.012962027959100477\n",
      "Training loss: -0.012879671791831294\n",
      "Training loss: -0.012745659138347293\n",
      "Training loss: -0.012690755608561519\n",
      "Training loss: -0.012788706064761223\n",
      "Training loss: -0.012876595954995256\n",
      "Training loss: -0.012794879418951613\n",
      "Training loss: -0.012845573169333083\n",
      "Training loss: -0.013046351571877798\n",
      "Training loss: -0.012981787122584678\n",
      "Training loss: -0.012947376493040149\n",
      "Training loss: -0.013004805478784773\n",
      "Training loss: -0.012952969261296876\n",
      "Training loss: -0.01296402155995011\n",
      "Training loss: -0.013045857909384433\n",
      "Training loss: -0.01280099294475607\n",
      "Training loss: -0.012968339652449519\n",
      "Training loss: -0.012899962161575351\n",
      "Training loss: -0.012950056442269334\n",
      "Training loss: -0.013047394339923744\n",
      "Training loss: -0.013048150159933188\n",
      "Training loss: -0.013033286453009368\n",
      "Training loss: -0.013009906665340916\n",
      "Training loss: -0.012803265461334595\n",
      "Training loss: -0.012886043201695691\n",
      "Training loss: -0.012907162890419946\n",
      "Training loss: -0.013045047809769799\n",
      "Training loss: -0.012957465966363569\n",
      "Training loss: -0.013179816171392664\n",
      "Training loss: -0.013161983419288028\n",
      "Training loss: -0.012807165829090026\n",
      "Training loss: -0.01316364113990967\n",
      "Training loss: -0.013010409366977107\n",
      "Training loss: -0.012859585630643117\n",
      "Training loss: -0.013013612624403235\n",
      "Training loss: -0.013066363562871743\n",
      "Training loss: -0.012986634049687657\n",
      "Training loss: -0.013119414761975721\n",
      "Training loss: -0.01300571635141745\n",
      "Training loss: -0.013013308000815165\n",
      "Training loss: -0.013005196399337894\n",
      "Training loss: -0.012867456083899146\n",
      "Training loss: -0.012949476415688568\n",
      "Training loss: -0.013140300730685214\n",
      "Training loss: -0.01316506191864386\n",
      "Training loss: -0.013069060471680787\n",
      "Training loss: -0.012951669795019133\n",
      "Training loss: -0.012963203159538476\n",
      "Training loss: -0.013113253243692644\n",
      "Training loss: -0.013090844962510976\n",
      "Training loss: -0.013108142302021966\n",
      "Training loss: -0.013037334154318046\n",
      "Training loss: -0.013115140030512938\n",
      "Training loss: -0.01308489393991035\n",
      "Training loss: -0.013219034953697308\n",
      "Training loss: -0.013107345738747457\n",
      "Training loss: -0.013089563664015348\n",
      "Training loss: -0.013104180159332516\n",
      "Training loss: -0.013227016606309393\n",
      "Training loss: -0.013047311689939585\n",
      "Training loss: -0.013188506524126092\n",
      "Training loss: -0.013149054983893672\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "\n",
    "        b_x = batch_x  # 64 batch size\n",
    "        b_y = batch_y.type(torch.LongTensor)  # 64 batch size\n",
    "        \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model_chk(b_x)\n",
    "        loss = criterion(output, b_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        #saves the model\n",
    "        torch.save({\n",
    "            'epoch': e,\n",
    "            'model_state_dict': model_chk.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': running_loss,\n",
    "            }, path+\"model_\"+str(e)+\".pt\")\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b009f1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=12, out_features=128, bias=True)\n",
       "  (1): Dropout(p=0.2, inplace=False)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (4): Dropout(p=0.1, inplace=False)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (7): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load = model_chk\n",
    "optimizer = optim.Adam(model_reg.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "\n",
    "checkpoint = torch.load(path+\"model_2.pt\")\n",
    "model_load.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model_load.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bac6d81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Test Data  70.57057057057057\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_test_tensor = Tensor(X_test.values)\n",
    "y_test = Tensor(np.array(y_test))\n",
    "z = model_load(X_test_tensor)\n",
    "\n",
    "yhat = list(z.argmax(1))\n",
    "y_test = list(y_test)\n",
    "\n",
    "print(\"Accuracy Score of Test Data \",accuracy_score(y_test,yhat) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150a558-d4dd-488b-b716-88e4c41a9301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
